{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SitemapsFromRobots.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PuqVX9f16Zbx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q gspread"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W3s6HNtwm9ib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Пере запуском - создать таблицу с названием A new spreadsheet и проверить чтобы в ней было 2 листа.\n",
        "На первый лист в А:А добавить список доменов вида domain.com (без http и последнего слэша). На втором листе - будет список карт сайтов из роботсов.\n"
      ]
    },
    {
      "metadata": {
        "id": "J4E7i3wqrM2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "857c3080-7843-464d-ed17-d9c067447a03"
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request as requests\n",
        "import urllib.error as error\n",
        "import re\n",
        "import ssl\n",
        "import itertools\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# SDK autorize\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "# Open sheet and read some data.\n",
        "worksheet = gc.open('A new spreadsheet').sheet1\n",
        "\n",
        "# Get all \"domain.com\" from Sheet1 \n",
        "sites = worksheet.get_all_values()\n",
        "\n",
        "# For SSL errors exception\n",
        "ctx = ssl.create_default_context()\n",
        "ctx.check_hostname = False\n",
        "ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "# HTTP types for sites without redirects\n",
        "types = ['https://', 'http://', 'https://www.', 'http://www.']\n",
        "\n",
        "# Open Sheet 2 and add some data.\n",
        "worksheet = gc.open('A new spreadsheet').get_worksheet(1)\n",
        "n = 1\n",
        "cell_data = set()\n",
        "\n",
        "# Get robots.txt and get Sitemap: string\n",
        "for site in sites:\n",
        "   for type in types:\n",
        "    urlGen = str(type + site[0] + '/robots.txt')\n",
        "    try: \n",
        "      response = requests.urlopen(urlGen, context=ctx)\n",
        "    except error.HTTPError as e:\n",
        "      print('HTTPError = ' + str(e.code))\n",
        "    except error.URLError as e:\n",
        "      print('URLError = ' + str(e.reason))\n",
        "    except httplib.HTTPException as e:\n",
        "      print('HTTPException')\n",
        "    except Exception:\n",
        "      import traceback\n",
        "      print('generic exception: ' + traceback.format_exc())\n",
        "    soup = BeautifulSoup(response.read())\n",
        "    p = re.findall('Sitemap:.*', str(soup))\n",
        "    for map in p:\n",
        "      cell_data.add(map)\n",
        "    print (p)\n",
        "    \n",
        "# Update cells in spreadsheet Sheet2\n",
        "for map in cell_data:\n",
        "  worksheet.update_cell(n, 1, map)\n",
        "  n += 1\n"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 193 of the file /usr/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
            "\n",
            " BeautifulSoup(YOUR_MARKUP})\n",
            "\n",
            "to this:\n",
            "\n",
            " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
            "\n",
            "  markup_type=markup_type))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['Sitemap: https://www.lun.ua/sitemap.xml']\n",
            "['Sitemap: https://www.lun.ua/sitemap.xml']\n",
            "['Sitemap: https://www.lun.ua/sitemap.xml']\n",
            "['Sitemap: https://www.lun.ua/sitemap.xml']\n",
            "['Sitemap: https://day.lun.ua/sitemap.xml']\n",
            "['Sitemap: https://day.lun.ua/sitemap.xml']\n",
            "['Sitemap: https://day.lun.ua/sitemap.xml']\n",
            "['Sitemap: https://day.lun.ua/sitemap.xml']\n",
            "['Sitemap: https://novostroyki.lun.ua/sitemap.xml']\n",
            "['Sitemap: https://novostroyki.lun.ua/sitemap.xml']\n",
            "['Sitemap: https://novostroyki.lun.ua/sitemap.xml']\n",
            "['Sitemap: https://novostroyki.lun.ua/sitemap.xml']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}